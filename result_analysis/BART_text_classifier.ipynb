{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19541,"status":"ok","timestamp":1716210003668,"user":{"displayName":"Kieffer Max","userId":"10634862561317901768"},"user_tz":-120},"id":"H0XJbKoa2XmX","outputId":"63c015b5-6a23-44eb-a060-f1c56a26383b"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":199034,"status":"ok","timestamp":1716210555561,"user":{"displayName":"Kieffer Max","userId":"10634862561317901768"},"user_tz":-120},"id":"WtVZvjJI2fz5","outputId":"60439677-4965-4448-96ff-87326aa2bc5e"},"outputs":[],"source":["# !unzip \"/content/drive/MyDrive/Google Colab/HumanML3D.zip\""]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1716210754022,"user":{"displayName":"Kieffer Max","userId":"10634862561317901768"},"user_tz":-120},"id":"orDUDLME2N66","outputId":"87a419f4-04b7-45b7-e14e-2257bd5c943d"},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/miniconda3/envs/digitalHumans/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stdout","output_type":"stream","text":["Using device: mps\n"]}],"source":["import os\n","from tqdm import tqdm\n","import torch\n","from transformers import pipeline\n","\n","ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n","EXTERNAL_REPOS_DIR = os.path.join(ROOT_DIR, \"external_repos\")\n","MOMASK_REPO_DIR = os.path.join(EXTERNAL_REPOS_DIR, \"momask-codes\")\n","# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","DEVICE = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n","# HUMAN_ML_DIR = os.path.join(ROOT_DIR, \"content\", \"HumanML3D\")\n","HUMAN_ML_DIR = os.path.join(MOMASK_REPO_DIR, \"dataset\", \"HumanML3D\")\n","\n","\n","print(f\"Using device: {DEVICE}\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":278,"status":"ok","timestamp":1716210754546,"user":{"displayName":"Kieffer Max","userId":"10634862561317901768"},"user_tz":-120},"id":"PhI3w7qq2N6-","outputId":"cc934357-a8f8-4ea5-c48b-dc44e9ceb429"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of text files loaded: 4384\n"]}],"source":["texts_path = os.path.join(HUMAN_ML_DIR, \"texts\")\n","test_txt_path = os.path.join(HUMAN_ML_DIR, \"test.txt\")\n","\n","# Load data\n","with open(test_txt_path, \"r\") as test_file:\n","    test_filenames = [line.strip() for line in test_file.readlines()]\n","\n","def read_text_file(filepath):\n","    with open(filepath, \"r\") as file:\n","        return [line.strip().split('#')[0] for line in file.readlines()]\n","\n","text_files_content = {}\n","\n","# Iterate through the list of filenames and load the corresponding text files\n","for filename in test_filenames:\n","    file_path = os.path.join(texts_path, filename + \".txt\")\n","    if os.path.exists(file_path):\n","        content = read_text_file(file_path)\n","        text_files_content[filename] = content\n","    else:\n","        print(f\"File {filename} not found in {texts_path}\")\n","\n","print(f\"Number of text files loaded: {len(text_files_content)}\")"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":909133,"status":"ok","timestamp":1716211821199,"user":{"displayName":"Kieffer Max","userId":"10634862561317901768"},"user_tz":-120},"id":"Ax9fZBVn2N6_","outputId":"b122a0c9-1812-4609-a7ae-03b4020ca1bf"},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing files:   0%|          | 20/4384 [00:04<15:43,  4.63it/s]"]},{"name":"stdout","output_type":"stream","text":["Zero-shot classification completed successfully!\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=DEVICE)\n","\n","# Define your candidate labels\n","candidate_labels = [\"dancing\", \"limbs\", \"emotions\"]\n","\n","# Define the number of top labels to consider\n","top_n = len(candidate_labels)\n","THRESHOLD = 0.87\n","\n","dancing = {}\n","limbs = {}\n","emotions = {}\n","\n","# Perform zero-shot classification in batches\n","for idx, (filename, lines) in enumerate(tqdm(text_files_content.items(), desc=\"Processing files: \")):\n","    for line in lines:\n","        result = classifier(line, candidate_labels)\n","\n","        for k in range(top_n):\n","            label = result['labels'][k]\n","            score = result['scores'][k]\n","            if label == \"dancing\" and score >= THRESHOLD:\n","                if filename in dancing:\n","                    dancing[filename].append((line, score))\n","                else:\n","                    dancing[filename] = [(line, score)]\n","            elif label == \"limbs\" and score >= THRESHOLD:\n","                if filename in limbs:\n","                    limbs[filename].append((line, score))\n","                else:\n","                    limbs[filename] = [(line, score)]\n","            elif label == \"emotions\" and score >= THRESHOLD:\n","                if filename in emotions:\n","                    emotions[filename].append((line, score))\n","                else:\n","                    emotions[filename] = [(line, score)]\n","\n","    if idx == 20:\n","        break\n","\n","print(\"Zero-shot classification completed successfully!\")"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","    \"004822\": [\n","        [\n","            \"person walking at a average pace forward, swaying arms and torso with a sense of swagger\",\n","            0.9761677980422974\n","        ]\n","    ],\n","    \"014457\": [\n","        [\n","            \"a person stands, bent slightly forward, holds onto something with both hands and swings their arms as if they were hitting a golf ball.\",\n","            0.9012690186500549\n","        ]\n","    ],\n","    \"002530\": [\n","        [\n","            \"the person takes 4 steps forward starting with his right foot.\",\n","            0.8770280480384827\n","        ]\n","    ],\n","    \"004945\": [\n","        [\n","            \"person is bent down trying to pick up stuff, left arm is moved to the back, picks up more stuff and touches back again while bending down\",\n","            0.9761883020401001\n","        ],\n","        [\n","            \"a person, searching for something with their right hand, picks up the item with their left hand and places it in something by their head.\",\n","            0.8705397844314575\n","        ]\n","    ],\n","    \"001969\": [\n","        [\n","            \"a person casually walks forwards, turns around, walks back, turns to the left, and backs up a few steps while raising both forearms level with the floor.\",\n","            0.9430326819419861\n","        ]\n","    ],\n","    \"005799\": [\n","        [\n","            \"man walks forward while upper body is leaning slightly to the left and steps are unbalanced and slow.\",\n","            0.9040858745574951\n","        ],\n","        [\n","            \"person staggers side to side from a standing position\",\n","            0.9288275241851807\n","        ],\n","        [\n","            \"a person hobbles around trying to walk.\",\n","            0.9886388182640076\n","        ]\n","    ],\n","    \"004124\": [\n","        [\n","            \"man walks forward moving hands and neck.\",\n","            0.9860209822654724\n","        ]\n","    ],\n","    \"012805\": [\n","        [\n","            \"person begins to move forward, begins to slide or skid, recovers on right leg and continues forward\",\n","            0.9425134658813477\n","        ]\n","    ],\n","    \"001168\": [\n","        [\n","            \"a person walks forward casually with a swagger to their hips.\",\n","            0.9006428718566895\n","        ],\n","        [\n","            \"a person walks forward with his arms at his side slowly.\",\n","            0.9688126444816589\n","        ]\n","    ],\n","    \"002246\": [\n","        [\n","            \"with hips swaying like a woman walking, this person takes 4 steps up the stairs, turns to the left on steps 5 & 6, then walks down the stairs in 4 more steps, walking back to where they started.\",\n","            0.8982986211776733\n","        ]\n","    ],\n","    \"000787\": [\n","        [\n","            \"a person walks steadily along a path while holding onto rails to keep balance.\",\n","            0.9116477370262146\n","        ],\n","        [\n","            \"a person walks forward carefully with arms extended.\",\n","            0.982372522354126\n","        ]\n","    ]\n","}\n"]}],"source":["import json\n","beauty = json.dumps(limbs, indent=4)\n","\n","print(beauty)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":518,"status":"ok","timestamp":1716211980324,"user":{"displayName":"Kieffer Max","userId":"10634862561317901768"},"user_tz":-120},"id":"iES0viWK2N6_","outputId":"84954fa3-7c70-4a3b-a21c-1285b9a5ebf6"},"outputs":[],"source":["for filename, lines in emotions.items():\n","    print(f\"Filename: {filename}\")\n","    for line in lines:\n","        print(f\"Line: {line[0]}\")\n","        print(f\"Score: {line[1]}\")\n","\n","    print()"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":272,"status":"ok","timestamp":1716211896245,"user":{"displayName":"Kieffer Max","userId":"10634862561317901768"},"user_tz":-120},"id":"N5LagUTA2N6_","outputId":"12a48309-4678-4b17-f1ce-5ee144dacaa2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 122 files with 'dancing' label\n","Found 3511 files with 'limbs' label\n","Found 6 files with 'emotions' label\n"]}],"source":["not_limbs = set(test_filenames) - set(limbs.keys())\n","not_limbs = sorted(list(not_limbs))\n","\n","print(f\"Found {len(dancing)} files with 'dancing' label\")\n","print(f\"Found {len(limbs)} files with 'limbs' label\")\n","print(f\"Found {len(emotions)} files with 'emotions' label\")\n","print(f\"Files without 'limbs' label: {not_limbs}\")"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":345,"status":"ok","timestamp":1716212857808,"user":{"displayName":"Kieffer Max","userId":"10634862561317901768"},"user_tz":-120},"id":"XWAlVcoh2N7A"},"outputs":[],"source":["# Function to write results to a text file\n","def save_filenames(output_path, category):\n","\n","    if isinstance(category, dict):\n","        with open(output_path, 'w') as f:\n","            for filename in category.keys():\n","                f.write(f\"{filename}\\n\")\n","            f.write(\"\\n\")\n","    elif isinstance(category, (set, list)):\n","        with open(output_path, 'w') as f:\n","            for filename in category:\n","                f.write(f\"{filename}\\n\")\n","            f.write(\"\\n\")\n","\n","save_filenames(\"/content/dancing.txt\", dancing)\n","save_filenames(\"/content/limbs.txt\", limbs)\n","save_filenames(\"/content/not_limbs.txt\", not_limbs)\n","save_filenames(\"/content/emotions.txt\", emotions)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"KJbmgMo2OFYz"},"outputs":[{"name":"stdout","output_type":"stream","text":["File  not found in /Users/maxkieffer/Documents/github/DigitalHumans/external_repos/momask-codes/dataset/HumanML3D/texts\n","Filename: 004822\n","Line: a person is walking in place at a slow pace.\n","Line: person walking at a average pace forward, swaying arms and torso with a sense of swagger\n","Line: a person walks in place.\n","\n","Filename: 014457\n","Line: the person swings a golf club.\n","Line: a person swings a golf club.\n","Line: a person stands, bent slightly forward, holds onto something with both hands and swings their arms as if they were hitting a golf ball.\n","\n","Filename: 009613\n","Line: the man runs back wards\n","Line: the person is running backwards quickly.\n","Line: a person jogs backwards, diagonally.\n","\n","Filename: 008463\n","Line: a man walks forward, then squats to pick something up with both hands, stands back up, and resumes walking.\n","Line: walking forward and then bending down.\n","Line: man walks along, then bends down and picks something up.\n","\n","Filename: 014160\n","Line: a person waves with his right hand.\n","Line: a person stands still, while waving with their right hand.\n","Line: a person is waving with their right hand.\n","\n"]}],"source":["# Load not limbs\n","not_limbs = read_text_file(\"test_classes/not_limbs.txt\")\n","\n","# Load files with no limbs\n","for filename in not_limbs:\n","    file_path = os.path.join(texts_path, filename + \".txt\")\n","    if os.path.exists(file_path):\n","        content = read_text_file(file_path)\n","        text_files_content[filename] = content\n","    else:\n","        print(f\"File {filename} not found in {texts_path}\")\n","\n","# Print first 5 files with no limbs\n","for idx, (filename, lines) in enumerate(text_files_content.items()):\n","    print(f\"Filename: {filename}\")\n","    for line in lines:\n","        print(f\"Line: {line}\")\n","    print()\n","\n","    if idx == 4:\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}
